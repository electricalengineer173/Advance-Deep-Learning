{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"Car_Price_Prediction (PIAIC 77161).ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/sadaqatali1234/Deep-learning-assigments/blob/main/Car_Price_Prediction_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"sMNQWyN0xU9q"},"source":["# Car Price Prediction::"]},{"cell_type":"markdown","metadata":{"id":"lRcwEJBbxU91"},"source":["Download dataset from this link:\n","\n","https://www.kaggle.com/hellbuoy/car-price-prediction"]},{"cell_type":"markdown","metadata":{"id":"6iwzOdWVxU92"},"source":["# Problem Statement::"]},{"cell_type":"markdown","metadata":{"id":"vdcrxOjJxU93"},"source":["A Chinese automobile company Geely Auto aspires to enter the US market by setting up their manufacturing unit there and producing cars locally to give competition to their US and European counterparts.\n","\n","They have contracted an automobile consulting company to understand the factors on which the pricing of cars depends. Specifically, they want to understand the factors affecting the pricing of cars in the American market, since those may be very different from the Chinese market. The company wants to know:\n","\n","Which variables are significant in predicting the price of a car\n","How well those variables describe the price of a car\n","Based on various market surveys, the consulting firm has gathered a large data set of different types of cars across the America market.\n","\n","# task::\n","We are required to model the price of cars with the available independent variables. It will be used by the management to understand how exactly the prices vary with the independent variables. They can accordingly manipulate the design of the cars, the business strategy etc. to meet certain price levels. Further, the model will be a good way for management to understand the pricing dynamics of a new market."]},{"cell_type":"markdown","metadata":{"id":"A9udJmRIxU94"},"source":["# WORKFLOW ::"]},{"cell_type":"markdown","metadata":{"id":"Mg0LFipjxU94"},"source":["1.Load Data\n","\n","2.Check Missing Values ( If Exist ; Fill each record with mean of its feature )\n","\n","3.Split into 50% Training(Samples,Labels) , 30% Test(Samples,Labels) and 20% Validation Data(Samples,Labels).\n","\n","4.Model : input Layer (No. of features ), 3 hidden layers including 10,8,6 unit & Output Layer with activation function relu/tanh (check by experiment).\n","\n","5.Compilation Step (Note : Its a Regression problem , select loss , metrics according to it)\n","6.Train the Model with Epochs (100) and validate it\n","\n","7.If the model gets overfit tune your model by changing the units , No. of layers , activation function , epochs , add dropout layer or add Regularizer according to the need .\n","\n","8.Evaluation Step\n","\n","9.Prediction"]},{"cell_type":"code","metadata":{"id":"6p7Jhz5_xU95"},"source":["# importing all libarires \n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xbu5dVklxU96"},"source":["# google mount \n","from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ed3u6UgMxU97"},"source":["# ----------------Step1-----------\n","\n","\n","\n","df = pd.read_csv(\"/content/drive/MyDrive/CarPrice_Assignment.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r_UdiL8rMMAk"},"source":["***Data cleaning and analyzing***"]},{"cell_type":"code","metadata":{"id":"T-NOrJvN0WjJ"},"source":["# ------------Step2-----------------\n","\n","\n","#check null values in data set\n","df.isnull().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q1mh6UfdCqoz"},"source":["#----------------------Step3-----------------\n","\n","\n","\n","\n","# dataframe spliting into input(X) & output(y)\n","X=df.iloc[:,:-1]\n","y=df.iloc[:,-1]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3OZ3H6BTVHOr"},"source":["# Drop all non_numeric features\n","X.drop(X.select_dtypes(include='object'),axis=1,inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pIe-zkdE3qs6"},"source":["\n","X_train=X.sample(frac=0.7, random_state=1,axis=0)\n","y_train=y.sample(frac=0.7, random_state=1,axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ls4tWALd6Pzz"},"source":["# spliting data into training data (X_test) as  training labels (y_test)\n","X_test=X.sample(frac=0.3, replace=True, random_state=1,axis=0)\n","y_test=y.sample(frac=0.3, replace=True, random_state=1,axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SCDVPUsm4ZaE"},"source":["# Check the shape of training data,testing data,training labels,testing labels\n","print(f\"shape of training data is :{X_train.shape}\\nshape of training label is :{y_train.shape}\\nshape of testing data is :{X_test.shape}\\nshape of testing label is :{y_test.shape}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tZHITtDV2RrM"},"source":["#convert training and testing data into numpy array and also change datatypes into Float\n","X_train=np.asarray(X_train).astype(\"float32\")\n","X_test=np.asarray(X_test).astype(\"float32\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6kW2_oHrSi-F"},"source":["#Data normalization \n","mean = X_train.mean(axis=0)\n","X_train-= mean\n","std = X_train.std(axis=0)\n","X_train/= std\n","X_test-= mean\n","X_test/= std"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fdeIgaOLX9GO"},"source":["# labels \n","y_mean = y_train.mean(axis=0)\n","y_train-= y_mean\n","y_std = y_train.std(axis=0)\n","y_train/= y_std\n","y_test-= y_mean\n","y_test/= y_std"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DDddSyUv8k4F"},"source":["# validation Data split from training Data\n","val_x=X_train[:50]\n","partial_x_train=X_train[50:]\n","val_y=y_train[:50]\n","partial_y_train=y_train[50:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3knFXQlZK3ug"},"source":["# importing all libariries\n","import tensorflow as tf\n","from keras import models,layers,optimizers,losses\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tzNVnHUf3ffq"},"source":["#--------------------Step 4-----------------------------\n","\n","\n","\n","\n","\n","# model buildup\n","network=models.Sequential()\n","network.add(layers.Dense(10,activation=\"relu\" ,input_shape=(X_train.shape[1],)))\n","network.add(layers.Dropout(0.2))\n","network.add(layers.Dense(8,activation=\"relu\"))\n","#network.add(layers.Dropout(0.2))\n","network.add(layers.Dense(6,activation=\"relu\"))\n","network.add(layers.Dense(1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v_nWZA0N6dvU"},"source":["#------------------------Step5---------------------------------\n","\n","\n","\n","# model compliling\n","network.compile(optimizer=\"rmsprop\",loss=\"mse\",metrics=[\"mae\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QliTGCi94XDc"},"source":["#-----------------------Step 6--------------------\n","\n","\n","\n","\n","\n","# model training on training data & validation data\n","history=network.fit(partial_x_train, partial_y_train,epochs=85, batch_size=1, verbose=1,validation_data=(val_x,val_y))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hzImMFI2PBVD"},"source":["# graph of training and validation loss\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","epochs = range(1, len(loss) + 1)\n","plt.plot(epochs, loss,\"go\",label='Training loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.grid()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wgYqTsNt5Fme"},"source":["#----------------Step 8------------------------\n","\n","\n","\n","\n","# model evaluation\n","network.evaluate(X_test,y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GDSGr6yI8UVr"},"source":["#--------------Step 9--------------------\n","\n","\n","\n","\n","#model predictions \n","#result=network.predict(X_test)\n","result_1=network.predict(X_test)\n","result_1[4]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XQBU2Sez8WWR"},"source":["#graph\n","y=result_1\n","y1=range(62)\n","x=y_test\n","plt.scatter(x, y1, label= \"Actual price\", color= \"blue\", marker= \"*\", s=100)\n","plt.scatter(y, y1, label= \"Predicted Price\", color= \"green\", marker= \"+\", s=100)\n","plt.xlabel('Price')\n","plt.ylabel('Rows')\n","plt.title('Actual price versus predicted price!')\n","plt.legend()\n","plt.grid()\n","plt.show()"],"execution_count":null,"outputs":[]}]}